{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SnakesCode_Sketch_v3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgrpg9JCLlqZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pBZSVp-isNh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224"
      ],
      "metadata": {
        "id": "nUOkYKa-Ml1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/SnakeTeam_SamsungAI/Venomous.zip (Unzipped Files)/Venomous',\n",
        "    labels =  'inferred',\n",
        "    label_mode = \"int\",    #int ou string\n",
        "    color_mode = 'rgb',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_width),\n",
        "    shuffle = True,\n",
        "    seed = 123,\n",
        "    validation_split = 0.1,\n",
        "    subset = \"training\",\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "ds_val= tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/SnakeTeam_SamsungAI/Venomous.zip (Unzipped Files)/Venomous',\n",
        "    labels =  'inferred',\n",
        "    label_mode = \"int\",    #int ou string\n",
        "    color_mode = 'rgb',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_width),\n",
        "    shuffle = True,\n",
        "    seed = 123,\n",
        "    validation_split = 0.1,\n",
        "    subset = \"validation\",\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "qCDgpFciQRbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.array(ds_train.class_names)\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "G8VpuNrSIfJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "ds_train = ds_train.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "ds_val = ds_val.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels."
      ],
      "metadata": {
        "id": "BxBMR4n5I6LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "aaMmtScZJ7H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in ds_train:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "X0r0oQy2J8qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_root = tf.keras.utils.get_file(\n",
        "#     'Venomous',\n",
        "#     'https://github.com/arjun921/Indian-Snakes-Dataset/tree/master/Venomous',\n",
        "#     untar=True,\n",
        "#     extract=True,\n",
        "#     archive_format='auto')"
      ],
      "metadata": {
        "id": "28Qye5FPQDS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_root"
      ],
      "metadata": {
        "id": "2T93GO5XDJD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# batch_size = 32\n",
        "# img_height = 224\n",
        "# img_width = 224\n",
        "\n",
        "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "#   str(data_root),\n",
        "#   labels = 'inferred',\n",
        "#   validation_split=0.2,\n",
        "#   subset=\"training\",\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size\n",
        "# )\n",
        "\n",
        "# val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "#   str(data_root),\n",
        "#   labels = 'inferred',\n",
        "#   validation_split=0.2,\n",
        "#   subset=\"validation\",\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size\n",
        "# )"
      ],
      "metadata": {
        "id": "fgy5e3WO6lUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n",
        "\n",
        "classifier_model = inception_v3 #@param [\"mobilenet_v2\", \"inception_v3\"] {type:\"raw\"}"
      ],
      "metadata": {
        "id": "6jGfMfjsLV80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(classifier_model, input_shape=IMAGE_SHAPE+(3,))\n",
        "])"
      ],
      "metadata": {
        "id": "giOMhyjqLSRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())"
      ],
      "metadata": {
        "id": "PHuCcsndOz7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gTN7M_GxDLx"
      },
      "source": [
        "### Run the classifier on a batch of images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "result_batch = classifier.predict(ds_train)"
      ],
      "metadata": {
        "id": "fltMmyd3Kq7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_names = imagenet_labels[tf.math.argmax(result_batch, axis=-1)]\n",
        "predicted_class_names"
      ],
      "metadata": {
        "id": "YTS-P0OIKstn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmvSWg9nxDLa"
      },
      "source": [
        "Check how these predictions line up with the images:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  plt.title(predicted_class_names[n])\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"sn{AI}ke predictions\")"
      ],
      "metadata": {
        "id": "RX1lKXmcKz4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV457OXreQP"
      },
      "source": [
        "### Download the headless model\n",
        "\n",
        "TensorFlow Hub also distributes models without the top classification layer. These can be used to easily perform transfer learning.\n",
        "\n",
        "Select a <a href=\"https://arxiv.org/abs/1801.04381\" class=\"external\">MobileNetV2</a> pre-trained model <a href=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\" class=\"external\">from TensorFlow Hub</a>. Any <a href=\"https://tfhub.dev/s?module-type=image-feature-vector&q=tf2\" class=\"external\">compatible image feature vector model</a> from TensorFlow Hub will work here, including the examples from the drop-down menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bw8Jf94DSnP"
      },
      "outputs": [],
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "restnet_v2 = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "feature_extractor_model = inception_v3 #@param [\"mobilenet_v2\", \"inception_v3\"] {type:\"raw\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHugQF-PD"
      },
      "source": [
        "Create the feature extractor by wrapping the pre-trained model as a Keras layer with [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer). Use the `trainable=False` argument to freeze the variables, so that the training only modifies the new classifier layer:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    feature_extractor_model,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)"
      ],
      "metadata": {
        "id": "bMHrlNb4SQU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QzVdu4ZhcDE"
      },
      "source": [
        "The feature extractor returns a 1280-long vector for each image (the image batch size remains at 32 in this example):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of7i-35F09ls"
      },
      "outputs": [],
      "source": [
        "feature_batch = feature_extractor_layer(image_batch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Attach a classification head\n",
        "\n",
        "To complete the model, wrap the feature extractor layer in a `tf.keras.Sequential` model and add a fully-connected layer for classification:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VgtBWyr6SpDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(image_batch)"
      ],
      "metadata": {
        "id": "G8QEU09cSujV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "AZgDPcg1SwHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbXQqIquFxQ"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Use `Model.compile` to configure the training process and add a `tf.keras.callbacks.TensorBoard` callback to create and store logs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xRx8Rjzm67O"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=log_dir,\n",
        "    histogram_freq=1) # Enable histogram computation for every epoch."
      ],
      "metadata": {
        "id": "knYDul5QVtJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58-BLV7dupJA"
      },
      "source": [
        "Now use the `Model.fit` method to train the model.\n",
        "\n",
        "To keep this example short, you'll be training for just 10 epochs. To visualize the training progress in TensorBoard later, create and store logs an a [TensorBoard callback](https://www.tensorflow.org/tensorboard/get_started#using_tensorboard_with_keras_modelfit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI0yAKd-nARd"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "history = model.fit(ds_train,\n",
        "                    validation_data=ds_val,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=tensorboard_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiDbmiAK_h03"
      },
      "source": [
        "Start the TensorBoard to view how the metrics change with each epoch and to track other scalar values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yVJar0MiT2t"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb__ZN8uFn-D"
      },
      "source": [
        "### Check the predictions\n",
        "\n",
        "Obtain the ordered list of class names from the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGbEf5l1I4jz"
      },
      "outputs": [],
      "source": [
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = class_names[predicted_id]\n",
        "print(predicted_label_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGbZxl9GZs-"
      },
      "source": [
        "Plot the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW3Ic_ZlwtrZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  plt.title(predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"sn{AI}ke predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single Image prediction"
      ],
      "metadata": {
        "id": "MFQ_ZOi932W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "m = str(input('Enter your image URL:'))\n",
        "img = image.load_img(m, target_size = (img_width, img_height))\n",
        "img_2 = image.img_to_array(img)\n",
        "img_2 = np.expand_dims(img, axis = 0)\n",
        "\n",
        "predicted_img = model.predict(img_2)\n",
        "\n",
        "predicted_id_img = tf.math.argmax(predicted_img, axis=-1)\n",
        "predicted_label = class_names[predicted_id_img]\n",
        "print(predicted_label)"
      ],
      "metadata": {
        "id": "Oe3rN3a0uwB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(predicted_label_batch.title())\n",
        "plt.axis('off')\n",
        "_ = plt.suptitle(\"sn{AI}ke prediction\")"
      ],
      "metadata": {
        "id": "CNZ2BgyA36K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.Sequential([ \n",
        "#      layers.Input((28, 28, 1)),\n",
        "#      layers.Conv2D(16, 3, padding='same'),\n",
        "#      layers.Conv2D(32, 3, padding='same'),\n",
        "#      layers.MaxPooling2D(),\n",
        "#      layers.Flatten(),\n",
        "#      layers.Dense(10),\n",
        "# ])"
      ],
      "metadata": {
        "id": "vYJ_ss5yM1fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def augment(x, y):\n",
        "#   image = tf.image.random_brightness(x, max_delta = 0.05)\n",
        "#   return image, y\n",
        "\n",
        "# ds_train = ds_train.map(augment)\n",
        "\n",
        "\n",
        "# for epochs in range(10):\n",
        "#   for x, y in ds_train:\n",
        "#     # train here"
      ],
      "metadata": {
        "id": "u5h1ORflYdtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#     optimizer = keras.optimizers.Adam(),\n",
        "#     loss = [\n",
        "#             keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "#     ],\n",
        "#     metrics = [\"accuracy\"],\n",
        "# )"
      ],
      "metadata": {
        "id": "-R8vWHznaZvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(ds_train, epochs = 10, verbose = 2)"
      ],
      "metadata": {
        "id": "vZqYcpdaazd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}